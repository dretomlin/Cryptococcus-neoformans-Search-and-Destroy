{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "'''\n",
    "LDA implementation using gensim\n",
    "note: much of the code is derived from the pipeline\n",
    "of priya dwivedi https://github.com/priya-dwivedi/Deep-Learning/blob/master/topic_modeling/LDA_Newsgroup.ipynb\n",
    "Collaborators: DeAndre Tomlinson, Emmet Flynn, Paul Brunts\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "import seaborn as sns\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'http', 'https', 'high', 'time', \n",
    "                    'table', 'read', 'number', 'also', 'show', 'elsevi'\n",
    "                  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Functions:\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemWords(texts):\n",
    "    ps = PorterStemmer()\n",
    "    stemmed = [[ps.stem(word) for word in text] for text in texts]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Initializing initial words from documents, positive/negative labels,\n",
    "#and the filename list for later use in the document\n",
    "data=[]\n",
    "testingData=[]\n",
    "trainingNameList=[]\n",
    "testingNameList=[]\n",
    "positiveNameList=[]\n",
    "trainingLabelList=[]\n",
    "testingLabelList=[]\n",
    "\n",
    "#Loads in the names of the files as names,\n",
    "#and  matches up to the names of the files in the same order\n",
    "for filename in os.listdir('positiveTextFiles'):\n",
    "    positiveNameList.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir('trainingFiles'):\n",
    "    trainingNameList.append(filename)\n",
    "    filePath='trainingFiles/'+filename\n",
    "    with open(filePath, 'r') as file:\n",
    "        x=file.read()\n",
    "        data.append(x)\n",
    "        trainingLabelList.append(1 if filename in positiveNameList else 0)\n",
    "\n",
    "for filename in os.listdir('testingFiles'):\n",
    "    testingNameList.append(filename)\n",
    "    filePath='testingFiles/'+filename\n",
    "    with open(filePath, 'r') as file:\n",
    "        x=file.read()\n",
    "        testingData.append(x)\n",
    "        testingLabelList.append(1 if filename not in positiveNameList else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input is an empty list, initialized in the previous set\n",
    "#This function does the data cleaning, remove punctionation\n",
    "#stop words, lemmatization, and enforces a minimum character limit\n",
    "#Output is a list of lists, with words from each document as a list\n",
    "def dataCleaning(data):\n",
    "    data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "    data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "    data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "    data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "    #remove words less than 4 characters\n",
    "    data = [re.sub(r'\\b\\w{1,3}\\b', '', sent) for sent in data]\n",
    "    # Remove Stop Words\n",
    "    data = remove_stopwords(data)\n",
    "\n",
    "\n",
    "    # Lemmatization keeping only noun, adj, vb \n",
    "    data = lemmatization(data, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    \n",
    "    #Stem words\n",
    "    data = stemWords(data)\n",
    "\n",
    "    data_cleaned = data\n",
    "    return(data_cleaned)\n",
    "\n",
    "trainD = dataCleaning(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Processes the list of list through gensim function, returns the cleaned data as a list of list again\n",
    "trainDwords = list(sent_to_words(trainD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create the appropiate object and dataframe for inital word analysis\n",
    "def wordsPreAnalysis(data):\n",
    "    words_list = [j for sub in data for j in sub]\n",
    "    freqwords = nltk.FreqDist(words_list)\n",
    "    words_df = pd.DataFrame({'word':list(freqwords.keys()), 'count':list(freqwords.values())})\n",
    "    return(freqwords, words_df)\n",
    "\n",
    "#Function to filter out words that cause outliers problems in the data (such as publisher names)\n",
    "def wordsFilter2(data):\n",
    "    # using list comprehension + list slicing \n",
    "    # Removing element from list of lists \n",
    "    wordfilter = ['elsevi']\n",
    "    for sub in data: \n",
    "        sub[:] = [ele for ele in sub if ele not in wordfilter] \n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqwords, words_df = wordsPreAnalysis(trainD)\n",
    "filt_words = wordsFilter2(trainD)\n",
    "filt_Dwords = list(sent_to_words(filt_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check plot to see if there are words that are erroneous/need cleaning. \n",
    "#Up to user discretion\n",
    "#freqwords.plot(20)\n",
    "#dflist = words_df.sort_values(by=[\"count\"], ascending=False)\n",
    "#dflist[dflist[\"count\"]<5]\n",
    "\n",
    "#Check to see if word was really filtered\n",
    "#filt_freqwords, filt_wordsDF = wordsPreAnalysis(filt_words)\n",
    "#filt_freqwords.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphSaver(filename):\n",
    "    '''\n",
    "    Function to save graphs to user's desktop\n",
    "    Saves to folder called \"graph_pictures\"\n",
    "    Input is a string with what you want the file to be called\n",
    "    '''\n",
    "    \n",
    "    directory = 'graph_pictures'\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    savepath = directory+'/'+filename\n",
    "    plt.savefig(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph that selects top N-most frequent words and charts them \n",
    "def freqWordsGraph(df, num, filename):\n",
    "    d = df.nlargest(columns=\"count\", n = num) \n",
    "    plt.figure(figsize=(20,5))\n",
    "    ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "    ax.set(ylabel = 'Count')\n",
    "    \n",
    "    graphSaver(filename)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqWordsGraph(words_df, 25, filename='unfiltered_words.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDict(words, freq):\n",
    "    # Create Dictionary\n",
    "    id2word = corpora.Dictionary(words)\n",
    "    id2word.filter_extremes(no_below = freq)\n",
    "    # Term Document Frequency\n",
    "    corpus = [id2word.doc2bow(word) for word in words]\n",
    "    return(id2word, corpus)\n",
    "\n",
    "id2word, corpus = createDict(filt_Dwords, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ldamodel for a single model. Used more as a trial run to test timing for the creation\n",
    "#for a particular topic number, and vary other parameters. \n",
    "#Precursor to the comput_eval_value function below\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eval_values(dictionary, corpus, texts, limit, start=2, step=5):\n",
    "    \"\"\"\n",
    "        Compute c_v coherence and perplexity for various number of topics\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        dictionary : Gensim dictionary\n",
    "        corpus : Gensim corpus\n",
    "        texts : List of input texts\n",
    "        limit : Max num of topics\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        model_list : List of LDA topic models\n",
    "        coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "        perplexity_values\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    perplexity_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        perplexity_values.append(model.log_perplexity(corpus))\n",
    "\n",
    "    return model_list, coherence_values, perplexity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list, coherence_values, perplexity_values = compute_eval_values(dictionary=id2word, corpus=corpus, texts=trainDwords, start=2, limit=10, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score of a singular model, precursor to the compute_eval_function\n",
    "coherence_model_lda = CoherenceModel(model=model_list[2], texts=filt_Dwords, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save('cneoformans_3kmodel')\n",
    "model_list[2].save('cneoformans_4kmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalsGrapher(coherences, perplexities, limit, start, step, filename):\n",
    "    #clear other plot\n",
    "    #plt.clf()\n",
    "    #plt.cla()\n",
    "    \n",
    "    x = range(start, limit, step)\n",
    "    for m, cv, pv in zip(x, coherences, perplexities):\n",
    "        print(\"Num Topics =\", m, \"has a Coherence Value of \", round(cv, 4), \" and has Perplexity Value of\", round(np.exp(-1. * pv), 4))\n",
    "    \n",
    "    # Graph coherence and perplexity over kTopics\n",
    "    fig, axs = plt.subplots(2,1, sharex=True)\n",
    "    plt.xlabel(\"Num Topics\")\n",
    "    axs[0].plot(x, coherence_values, color='green')\n",
    "    axs[0].set_ylabel(\"Coherence score\")\n",
    "    axs[0].legend(title =\"Coherence\", loc='best')\n",
    "\n",
    "    axs[1].plot(x, perplexity_values, color='blue')\n",
    "    axs[1].set_ylabel(\"Perplexity score\")\n",
    "    axs[1].legend(title=\"Perplexity\", loc='best')\n",
    "    \n",
    "    graphSaver(filename)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalsGrapher(coherence_values, perplexity_values, 10, 2, 1, filename='coh-perp-plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCountImpMaker(model, data, filename):\n",
    "    '''\n",
    "    Function to display word count and weight of each word for each topic\n",
    "    Good visual indicator for analysis\n",
    "    Input is the model, 2d list of words, and a filename to save to\n",
    "    '''\n",
    "    topics = model.show_topics(formatted=False)\n",
    "    data_flat = [w for w_list in data for w in w_list]\n",
    "    counter = Counter(data_flat)\n",
    "\n",
    "    out = []\n",
    "    for i, topic in topics:\n",
    "        for word, weight in topic:\n",
    "            out.append([word, i , weight, counter[word]])\n",
    "\n",
    "    df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "    # Plot Word Count and Weights of Topic Keywords\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14,5), sharey=True, dpi=160)\n",
    "    cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "        ax_twin = ax.twinx()\n",
    "        ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "        ax.set_ylabel('Word Count', color=cols[i])\n",
    "        ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 3500)\n",
    "        ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "        ax.tick_params(axis='y', left=False)\n",
    "        ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "        ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "    fig.tight_layout(w_pad=2)    \n",
    "    fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05) \n",
    "    \n",
    "    graphSaver(filename)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.colors as mcolors\n",
    "wordCountImpMaker(model_list[2], filt_Dwords, filename='word-importance-graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "#Visualizaton of topics in an html format for more analysis purposes\n",
    "lda_display = pyLDAvis.gensim.prepare(model_list[2], corpus, id2word, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.save_html(lda_display, 'lda_4k_vis.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Processing for testing corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testD = dataCleaning(testingData)\n",
    "testDwords = list(sent_to_words(testD))\n",
    "freqTestwords, wordsTestDf = wordsPreAnalysis(testDwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqTestwords.plot(20)\n",
    "dflist = wordsTestDf.sort_values(by=[\"count\"], ascending=False)\n",
    "dflist[dflist[\"count\"] < 5].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqWordsGraph(wordsTestDf, 25, filename='unfiltered_test_words.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2wordTest, corpusTest = createDict(testDwords, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(model, corpus, texts, kTopics):\n",
    "    '''\n",
    "    Function for grabbing topics and probabilities from lda model\n",
    "    First part in process to export values to csvs\n",
    "    Inputs are the model, text corpus, 2d list of words, and number of topics\n",
    "    '''\n",
    "    # Initialize dataframe to return and empty list\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    series_list=[]\n",
    "    \n",
    "    for i in range(kTopics):\n",
    "        series_list.append(0)\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(model[corpus]):\n",
    "        row = sorted(row[0], key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            wp = model.show_topic(topic_num)\n",
    "            series_list[topic_num]=prop_topic\n",
    "            #sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "        sent_topics_df=sent_topics_df.append(pd.Series([series_list[i] for i in range(len(series_list))]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    #sent_topics_df.columns = ['Topic_0', 'Topic_1', 'Topic_2']\n",
    "    # Add original text to the end of the output\n",
    "    sent_topics_df['contents'] = texts\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicProbs2csv(df, labelList, nameList, kTopics, filename):\n",
    "    '''\n",
    "    Function to send topic probabilities to csv file\n",
    "    '''\n",
    "    \n",
    "    df['label'] = labelList\n",
    "    df['name'] = nameList\n",
    "    \n",
    "    # Show\n",
    "    names = ['topic_{}'.format(i) for i in range(len(df.columns.values.tolist()) - 3)]+['contents', 'label', 'name'] \n",
    "    df.columns = names\n",
    "    \n",
    "    # Below we pull into the csv only the columns associated with the topics\n",
    "    # and the labels. (this is the first kTopics columns and the second column from the end\n",
    "    csv = df[names[:kTopics]+[names[-2]]].copy().to_csv(filename, index=False)\n",
    "    csv_printout = df[names[:kTopics]+[names[-2]]].copy().to_csv(index=False)\n",
    "    print(csv_printout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_sents_keywords = format_topics_sentences(lda_model, corpus, filt_Dwords, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing_topic_keywords = format_topics_sentences(lda_model, corpusTest, testDwords, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCsvfile = 'ltg_3k_testing.csv'\n",
    "testCsv = topicProbs2csv(df_testing_topic_keywords, testingLabelList, testingNameList, 3, testCsvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainCsvfile = 'ltg_3k_training.csv'\n",
    "trainCsv = topicProbs2csv(df_topic_sents_keywords, trainingLabelList, trainingNameList, 3, trainCsvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4test_topkeywords = format_topics_sentences(model_list[2], corpusTest, testDwords, 4)\n",
    "df_4train_topkeywords = format_topics_sentences(model_list[2], corpus, filt_Dwords, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCsvfile = 'ltg_4k_testing.csv'\n",
    "testCsv = topicProbs2csv(df_4test_topkeywords, testingLabelList, testingNameList, 4, testCsvfile)\n",
    "trainCsvfile = 'ltg_4k_training.csv'\n",
    "trainCsv = topicProbs2csv(df_4train_topkeywords, trainingLabelList, trainingNameList, 4, trainCsvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BIGRAMS AND TRIGRAMS DO NOT WORK. UNIGRAM ONLY.\n",
    "#not entirely sure about nthreshold\n",
    "# Build the bigram and trigram models\n",
    "#nthreshold=100\n",
    "#bigram = gensim.models.Phrases(data_words, min_count=5, threshold=nthreshold) # higher threshold fewer phrases.\n",
    "#trigram = gensim.models.Phrases(bigram[data_words], threshold=nthreshold)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "#bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "#trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "vectorizer = CountVectorizer(analyzer='word',       \n",
    "                             min_df=10,                        # minimum reqd occurences of a word \n",
    "                             stop_words='english',             # remove stop words\n",
    "                             lowercase=True,                   # convert all words to lowercase\n",
    "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
    "                             # max_features=50000,             # max number of uniq words\n",
    "                            )\n",
    "trainDwords_vec = vectorizer.fit_transform(filt_words)\n",
    "\n",
    "GRID SEARCH TAKES TOO LONG, BUT WOULD BE GREAT TO IMPLEMENT\n",
    "# Define Search Param\n",
    "search_params = {'n_components': [1,2,3]}\n",
    "\n",
    "# Init the Model\n",
    "lda = LatentDirichletAllocation()\n",
    "\n",
    "# Init Grid Search Class\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "model.fit(trainDwords_vec)\n",
    "\n",
    "# Best Model\n",
    "#best_lda_model = model.best_estimator_\n",
    "\n",
    "# Model Parameters\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "\n",
    "# Log Likelihood Score\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "\n",
    "# Perplexity\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(data_vectorized))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
